{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPG-EEC-T01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP76wWxtJzMD"
      },
      "source": [
        "# Classifying epileptic seizures from EEG data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhK_khGdKZJS"
      },
      "source": [
        "## KNN Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2kjyBSTKg94"
      },
      "source": [
        "### Importing necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3vUoKPAXbyR",
        "outputId": "11f0a763-f3fc-4f59-f7d1-421645f5b6e4"
      },
      "source": [
        "!pip install --upgrade scikit-learn\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "import pickle\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.neighbors import LocalOutlierFactor, KNeighborsRegressor, KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import (train_test_split, cross_val_score,\n",
        "GridSearchCV, StratifiedKFold, KFold)\n",
        "\n",
        "from sklearn.preprocessing import (StandardScaler, Normalizer, RobustScaler,\n",
        "QuantileTransformer, PowerTransformer, LabelEncoder, OneHotEncoder, OrdinalEncoder)\n",
        "\n",
        "from sklearn.metrics import (classification_report, mean_squared_error, \n",
        "confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay, accuracy_score,\n",
        "balanced_accuracy_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 5.6MB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.23.2 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_SRdCzuKqqv"
      },
      "source": [
        "### Initial exploration of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIkg-oVOQEqr",
        "outputId": "8b4d76d6-de64-43b7-dd2b-718636148e7f"
      },
      "source": [
        "# Loading the data from .csv\n",
        "data = pd.read_csv('Epileptic Seizure Recognition.csv', index_col = 0)\n",
        "\n",
        "# Re-labelling all four non-epileptic pacient classes to 0\n",
        "data.loc[data[\"y\"] > 1 , \"y\"] = 0\n",
        "\n",
        "# Printing dimensions of the data\n",
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11500, 179)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlMF7PciK0F2"
      },
      "source": [
        "### Splitting data into training and validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlK4wQCqj-L0",
        "outputId": "b769f8f2-0609-4926-e625-44998a547ddb"
      },
      "source": [
        "# Separate Data into a Training and Validation Datasets\n",
        "test_size = 0.20 # Allocating 80/20 % split of the data for train/test\n",
        "seed = 10\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data.drop(axis=1,labels=[\"y\"]), \n",
        "                                                    data[\"y\"],\n",
        "                                                    test_size=test_size, \n",
        "                                                    random_state=seed,\n",
        "                                                    stratify=data[\"y\"])\n",
        "\n",
        "# Printing the dimensions of the training and validation datasets\n",
        "print(f\"Train x: {x_train.shape}\\nTrain y: {y_train.shape}\")\n",
        "print(f\"Test x: {x_test.shape}\\nTest y   : {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train x: (9200, 178)\n",
            "Train y: (9200,)\n",
            "Test x: (2300, 178)\n",
            "Test y   : (2300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAIZlN0VLEX-"
      },
      "source": [
        "### Train a baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXjT4r-m_GPo",
        "outputId": "f09a9c6f-5c91-4920-e832-a0de44b6857f"
      },
      "source": [
        "# Train a baseline\n",
        "\n",
        "# instantiate a knn object\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# train the model\n",
        "knn.fit(x_train, y_train)\n",
        "\n",
        "# predict\n",
        "y_pred_knn = knn.predict(x_test)\n",
        "\n",
        "# evaluate\n",
        "print(\"Accuracy:\", balanced_accuracy_score(y_test, y_pred_knn))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.80625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7QACIlZLGlX"
      },
      "source": [
        "### Create a pipeline of different normalization methods to test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLpNC40WEVvK"
      },
      "source": [
        "# Create a PIPELINE to investigate different Normalization techniques\n",
        "\n",
        "# Standardize the dataset\n",
        "pipelines_list = []\n",
        "pipelines_list.append(('NonScaledKnn', \n",
        "                  Pipeline([('KNN',\n",
        "                             KNeighborsClassifier(n_neighbors=5,n_jobs=-1))])))\n",
        "pipelines_list.append(('ScaledKnn', \n",
        "                  Pipeline([('Scaler', \n",
        "                             StandardScaler()),\n",
        "                            ('KNN',\n",
        "                             KNeighborsClassifier(n_neighbors=5, n_jobs=-1))])))\n",
        "\n",
        "pipelines_list.append(('NormalizedKnn', \n",
        "                  Pipeline([('Normalizer', \n",
        "                             Normalizer()),\n",
        "                            ('KNN',\n",
        "                             KNeighborsClassifier(n_neighbors=5, n_jobs=-1))])))\n",
        "\n",
        "pipelines_list.append(('RobustedKnn', \n",
        "                  Pipeline([('Robust', \n",
        "                             RobustScaler()),\n",
        "                            ('KNN',\n",
        "                             KNeighborsClassifier(n_neighbors=5, n_jobs=-1))])))\n",
        "\n",
        "pipelines_list.append(('QuantiledKnn', \n",
        "                  Pipeline([('Quantile', \n",
        "                             QuantileTransformer()),\n",
        "                            ('KNN',\n",
        "                             KNeighborsClassifier(n_neighbors=5, n_jobs=-1))])))\n",
        "\n",
        "pipelines_list.append(('PoweredKnn', \n",
        "                  Pipeline([('Power', \n",
        "                             PowerTransformer()),\n",
        "                            ('KNN',\n",
        "                             KNeighborsClassifier(n_neighbors=5, n_jobs=-1))])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSOUiupGLFK_"
      },
      "source": [
        "Test pipeline of methods with cross-validation to infer best technique for the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBVyKP2iCz11",
        "outputId": "2a5e6097-14bf-404d-fbe9-3834b91757cc"
      },
      "source": [
        "# Cross-validation allows us to compare different \n",
        "# machine learning methods and get a sense of how\n",
        "# well they will work in practice\n",
        "\n",
        "# Test options and evaluation metric\n",
        "num_folds = 10\n",
        "scoring = 'balanced_accuracy'\n",
        "\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "for name, model in pipelines_list:\n",
        "  # k-fold size\n",
        "  kfold = KFold(n_splits=num_folds)\n",
        "  # cross validation\n",
        "  cv_results = cross_val_score(model, x_train, y_train,cv=kfold,scoring=scoring)\n",
        "  # store results\n",
        "  results.append(-cv_results)\n",
        "  names.append(name)\n",
        "  print(\"%s Mean: %f Std: %f\" % (name, \n",
        "                                      cv_results.mean(), \n",
        "                                      cv_results.std()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NonScaledKnn Mean: 0.806920 Std: 0.012230\n",
            "ScaledKnn Mean: 0.807829 Std: 0.013609\n",
            "NormalizedKnn Mean: 0.783202 Std: 0.016920\n",
            "RobustedKnn Mean: 0.805849 Std: 0.011464\n",
            "QuantiledKnn Mean: 0.635744 Std: 0.013276\n",
            "PoweredKnn Mean: 0.808533 Std: 0.014048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfjG1MR4LIN3"
      },
      "source": [
        "### Hyperparameter tuning with Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQCAXULxJTnv",
        "outputId": "a73a0fe4-5edc-4301-a73d-21e319599d09"
      },
      "source": [
        "# KNN Algorithm tuning (beat the baseline)\n",
        "\n",
        "# hyperparameter\n",
        "k_values = np.array([3,5,11,15,20,25])\n",
        "weights = ['uniform','distance']\n",
        "algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "metric = [1,2]\n",
        "\n",
        "# number of combinations\n",
        "models = (len(k_values) * len(weights) * len(algorithm) * len(metric))\n",
        "rounds = models * num_folds\n",
        "\n",
        "print(f\"Number of models: {models}\")\n",
        "print(f\"Complexity of evaluation: {rounds} rounds\")\n",
        "\n",
        "param_grid = dict(n_neighbors=k_values, \n",
        "                  weights=weights,\n",
        "                  algorithm=algorithm,\n",
        "                  p=metric)\n",
        "\n",
        "# Instantiate a normalization algorithm\n",
        "pt = PowerTransformer()\n",
        "# Learning the stats from feature\n",
        "pt.fit(x_train)\n",
        "# Transform x train\n",
        "scaler = pt.transform(x_train)\n",
        "\n",
        "# instantiate a model\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "# Test options and evaluation metric\n",
        "num_folds = 10\n",
        "scoring = 'balanced_accuracy'\n",
        "\n",
        "# Grid Searching with cross-validation\n",
        "kfold = KFold(n_splits=num_folds)\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=param_grid, \n",
        "                    scoring=scoring,\n",
        "                    cv=kfold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of models: 96\n",
            "Complexity of evaluation: 960 rounds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqYCuLvFLJsQ"
      },
      "source": [
        "Evaluate performance of best model found"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15EC40MkKbR8"
      },
      "source": [
        "# train the model\n",
        "grid_result = grid.fit(scaler, y_train)\n",
        "\n",
        "# Print results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, \n",
        "                             grid_result.best_params_))\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjYsv9GOUd8N",
        "outputId": "37f37991-33af-4c02-de95-3a90d8679958"
      },
      "source": [
        "# predict using the best estimator\n",
        "# pay attention in normalizer instance that was the same used in the train\n",
        "\n",
        "predict = grid_result.best_estimator_.predict(pt.transform(x_test))\n",
        "\n",
        "print(\"Accuracy:\", balanced_accuracy_score(y_test, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8290760869565217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kDkOnALMRI"
      },
      "source": [
        "### Deploy model to production and import it from saved file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRPoo52-NyUe"
      },
      "source": [
        "# Save the model using pickle\n",
        "with open('pipe2.pkl', 'wb') as file:\n",
        "  pickle.dump(grid_result, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZvyTxVvU_0K",
        "outputId": "6f563994-631a-48df-b120-987ae46609ce"
      },
      "source": [
        "# Under the production environment [pickle]\n",
        "with open('pipe2.pkl', 'rb') as file:\n",
        "  model = pickle.load(file)\n",
        "\n",
        "predict = model.best_estimator_.predict(pt.transform(x_test))\n",
        "print(\"Accuracy:\", balanced_accuracy_score(y_test, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8290760869565217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZC67dGBL4XW"
      },
      "source": [
        "## Random Forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aM2bFd-CIwC"
      },
      "source": [
        "### Import necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH4BSWZMCRsF"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EpPQF8nC2Y8"
      },
      "source": [
        "### Train a baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fwRd3TcC_Y6",
        "outputId": "195adcbd-78e1-4576-881b-98b76f3ffb41"
      },
      "source": [
        "# Random Forest using RandomForestClassifier\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500,\n",
        "                                 max_leaf_nodes=16, \n",
        "                                 random_state=42)\n",
        "rnd_clf.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "predict = rnd_clf.predict(x_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", balanced_accuracy_score(y_test, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9353260869565218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZEpSVKvE-sJ"
      },
      "source": [
        "### Hyperparameter tuning with Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zolYqVhzF-PK"
      },
      "source": [
        "# global varibles\n",
        "seed = 15\n",
        "num_folds = 10\n",
        "#scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
        "scoring = 'balanced_accuracy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzvYpsgfFt3e",
        "outputId": "c97ee16e-c5ab-4f0e-e8af-69f11eff66e0"
      },
      "source": [
        "# See documentation for more info\n",
        "# https://scikit-learn.org/stable/auto_examples/compose/plot_compare_reduction.html#sphx-glr-auto-examples-compose-plot-compare-reduction-py\n",
        "\n",
        "# create a dictionary with the hyperparameters\n",
        "search_space = [{\"n_estimators\": [100,200,300,400],\n",
        "                 \"criterion\": [\"gini\",\"entropy\"],\n",
        "                 \"max_leaf_nodes\": [4,16,32,64,128],\n",
        "                 \"random_state\": [seed],}]\n",
        "\n",
        "# create grid search\n",
        "kfold = StratifiedKFold(n_splits=num_folds,random_state=seed,shuffle=True)\n",
        "model = RandomForestClassifier()\n",
        "# see other scoring\n",
        "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "\n",
        "grid = RandomizedSearchCV(estimator=model, \n",
        "                    param_distributions=search_space,\n",
        "                    n_iter=20,\n",
        "                    cv=kfold,\n",
        "                    verbose = 2,\n",
        "                    scoring=scoring,\n",
        "                    return_train_score=True,\n",
        "                    n_jobs=-1,\n",
        "                    refit=\"Accuracy\")\n",
        "\n",
        "# fit grid search\n",
        "grid_result = grid.fit(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 11.2min\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 39.3min\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 47.6min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dp-CYOiGhG6"
      },
      "source": [
        "Evaluate performance of best model found"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWzXOGK7GhG6"
      },
      "source": [
        "# Print results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, \n",
        "                             grid_result.best_params_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KChaXZLGhG6",
        "outputId": "ef2ec37c-0655-4609-f25c-e696a1c60048"
      },
      "source": [
        "# predict using the best estimator\n",
        "\n",
        "predict = grid_result.best_estimator_.predict(x_test)\n",
        "\n",
        "print(\"Accuracy:\", balanced_accuracy_score(y_test, predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9595108695652174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaVSKmGsFEVT"
      },
      "source": [
        "### Deploy model to production and import it from saved file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsKFgn8KFvRF"
      },
      "source": [
        "# Save the model using pickle\n",
        "with open('pipeRF2.pkl', 'wb') as file:\n",
        "  pickle.dump(grid_result, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yXxN5TLFyhc"
      },
      "source": [
        "# Under the production environment [pickle]\n",
        "with open('pipeRF2.pkl', 'rb') as file:\n",
        "  model = pickle.load(file)\n",
        "\n",
        "predict = model.best_estimator_.predict(pt.transform(x_test))\n",
        "print(\"Accuracy:\", balanced_accuracy_score(y_test, predict))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}